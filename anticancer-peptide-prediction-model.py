# -*- coding: utf-8 -*-
"""Hybrid_QSAR_aac_aab_pcb_pcp.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MomHZ5NTmz9dcSDmg0ZcOdc4yg0LJyum
"""

#making Environment
! wget https://repo.anaconda.com/miniconda/Miniconda3-py37_4.8.2-Linux-x86_64.sh
! chmod +x Miniconda3-py37_4.8.2-Linux-x86_64.sh
! bash ./Miniconda3-py37_4.8.2-Linux-x86_64.sh -b -f -p /usr/local
import sys
sys.path.append('/usr/local/lib/python3.7/site-packages/')

! wget https://github.com/raghavagps/Pfeature/raw/master/PyLib/Pfeature.zip

#! unzip Pfeature.zip

#Install Pfeature zip file in local machine and unzip the file
from zipfile import ZipFile

# specifying the zip file name
file_name = "/content/Pfeature.zip"

with ZipFile(file_name, 'r') as zip:
	# printing all the contents of the zip file
	zip.printdir()

	# extracting all the files
	print('Extracting all the files now...')
	zip.extractall()
	print('Done!')

# Commented out IPython magic to ensure Python compatibility.
# % cd Pfeature

import pandas as pd

with open('/content/anticancer_ENNAACT.txt', 'r') as f:
    content = f.readlines()

n = len(content)


label = list('[content[i].strip() for i in range(0,n,2)]')
seq = [content[i].strip() for i in range(1,n,2)]
s1 = pd.Series(label)
s2 = pd.Series(seq)
df1 = pd.DataFrame({'label':s1.reindex(s2.index), 'seq':s2})
df1

! cat /content/anticancer_ENNAACT.txt

df1.seq[{12,10}]

print ("The original string is : " +  df1.seq[0] )
res = len(df1.seq[0])
print ("The number of words in string are : " +  str(res))

df1.value_counts

import pandas as pd

with open('/content/non-anticancer_ENNAACT.txt', 'r') as f:
    content = f.readlines()

n = len(content)

label = [content[i].strip() for i in range(0,n,2)]
seq = [content[i].strip() for i in range(1,n,2)]

df2 = pd.DataFrame({'label':label,
                   'sequence':seq})
df2

! cat /content/non-anticancer_ENNAACT.txt

import pandas as pd
from Pfeature.pfeature import aac_wp

def aac(input):
  a = input.rstrip('txt')
  output = a + 'aac.csv'
  df_out = aac_wp(input, output)
  df_in = pd.read_csv(output)
  return df_in

  aac('/content/anticancer_ENNAACT.txt')

aac('/content/anticancer_ENNAACT.txt')

import pandas as pd
from Pfeature.pfeature import aac_wp

def aac(input):
  a = input.rstrip('txt')
  output = a + 'aac.csv'
  df_out = aac_wp(input, output)
  df_in = pd.read_csv(output)
  return df_in

  aac('/content/non-anticancer_ENNAACT.txt')

aac('/content/non-anticancer_ENNAACT.txt')

import pandas as pd
from Pfeature.pfeature import aab_wp

def aab(input):
  a = input.rstrip('txt')
  output = a + 'aab.csv'
  df_out = aab_wp(input,output)
  df_in = pd.read_csv(output)
  return df_in

feature = aab('/content/non-anticancer_ENNAACT.txt')
feature

import pandas as pd
from Pfeature.pfeature import aab_wp

def aab(input):
  a = input.rstrip('txt')
  output = a + 'pat.csv'
  df_out = aab_wp(input, output)
  df_in = pd.read_csv(output)
  return df_in

feature = aab('/content/anticancer_ENNAACT.txt')
feature

import pandas as pd
from Pfeature.pfeature import pcb_wp

def pcb(input):
  a = input.rstrip('txt')
  output = a + 'pcb.csv'
  df_out = pcb_wp(input, output)
  df_in = pd.read_csv(output)
  return df_in

feature = pcb('/content/non-anticancer_ENNAACT.txt')
feature

import pandas as pd
from Pfeature.pfeature import pcb_wp

def pcb(input):
  a = input.rstrip('txt')
  output = a + 'pcb.csv'
  df_out = pcb_wp(input, output)
  df_in = pd.read_csv(output)
  return df_in

feature = pcb('/content/anticancer_ENNAACT.txt')
feature

import pandas as pd
from Pfeature.pfeature import pcp_wp

def pcp(input):
  a = input.rstrip('txt')
  output = a + 'pcp.csv'
  df_out = pcp_wp(input, output)
  df_in = pd.read_csv(output)
  return df_in

feature = pcp('/content/anticancer_ENNAACT.txt')
feature

import pandas as pd
from Pfeature.pfeature import pcp_wp

def pcp(input):
  a = input.rstrip('txt')
  output = a + 'pcp.csv'
  df_out = pcp_wp(input, output)
  df_in = pd.read_csv(output)
  return df_in

feature = pcp('/content/non-anticancer_ENNAACT.txt')
feature

pos = '/content/anticancer_ENNAACT.txt'
neg = '/content/non-anticancer_ENNAACT.txt'

def feature_calc(po, ne, feature_name):
  # Calculate feature
  po_feature = feature_name(po)
  ne_feature = feature_name(ne)
  # Create class labels
  po_class = pd.Series(['ACP' for i in range(len(po_feature))])
  ne_class = pd.Series(['non-ACP' for i in range(len(ne_feature))])
  # Combine po and ne
  po_ne_class = pd.concat([po_class, ne_class], axis=0)
  po_ne_class.name = 'class'
  po_ne_feature = pd.concat([po_feature, ne_feature], axis=0)
  # Combine feature and class
  df = pd.concat([po_ne_feature, po_ne_class], axis=1)
  return df

feature1 = feature_calc(pos, neg, aac) # Pattern Binary Profile
#feature = feature_calc(pos, neg, dpc) # DPC
#feature = feature_calc(pos, neg, pcp) #paac
feature1

pos = '/content/anticancer_ENNAACT.txt'
neg = '/content/non-anticancer_ENNAACT.txt'

def feature_calc(po, ne, feature_name):
  # Calculate feature
  po_feature = feature_name(po)
  ne_feature = feature_name(ne)
  # Create class labels
  po_class = pd.Series(['ACP' for i in range(len(po_feature))])
  ne_class = pd.Series(['non-ACP' for i in range(len(ne_feature))])
  # Combine po and ne
  po_ne_class = pd.concat([po_class, ne_class], axis=0)
  po_ne_class.name = 'class2'
  po_ne_feature = pd.concat([po_feature, ne_feature], axis=0)
  # Combine feature and class
  df = pd.concat([po_ne_feature, po_ne_class], axis=1)
  return df

feature2 = feature_calc(pos, neg, aab) # AAB
#feature2 = feature_calc(pos, neg, atb)
#feature2 = feature_calc(pos, neg, pat) #paac
feature2

pos = '/content/anticancer_ENNAACT.txt'
neg = '/content/non-anticancer_ENNAACT.txt'

def feature_calc(po, ne, feature_name):
  # Calculate feature
  po_feature = feature_name(po)
  ne_feature = feature_name(ne)
  # Create class labels
  po_class = pd.Series(['ACP' for i in range(len(po_feature))])
  ne_class = pd.Series(['non-ACP' for i in range(len(ne_feature))])
  # Combine po and ne
  po_ne_class = pd.concat([po_class, ne_class], axis=0)
  po_ne_class.name = 'class3'
  po_ne_feature = pd.concat([po_feature, ne_feature], axis=0)
  # Combine feature and class
  df = pd.concat([po_ne_feature, po_ne_class], axis=1)
  return df

feature3 = feature_calc(pos, neg, pcb) #PCB
#feature2 = feature_calc(pos, neg, atb) # Binary Pattern
#feature2 = feature_calc(pos, neg, pat) #paac
feature3

pos = '/content/anticancer_ENNAACT.txt'
neg = '/content/non-anticancer_ENNAACT.txt'

def feature_calc(po, ne, feature_name):
  # Calculate feature
  po_feature = feature_name(po)
  ne_feature = feature_name(ne)
  # Create class labels
  po_class = pd.Series(['ACP' for i in range(len(po_feature))])
  ne_class = pd.Series(['non-ACP' for i in range(len(ne_feature))])
  # Combine po and ne
  po_ne_class = pd.concat([po_class, ne_class], axis=0)
  po_ne_class.name = 'class4'
  po_ne_feature = pd.concat([po_feature, ne_feature], axis=0)
  # Combine feature and class
  df = pd.concat([po_ne_feature, po_ne_class], axis=1)
  return df

feature4 = feature_calc(pos, neg, pcp) # AAC
#feature2 = feature_calc(pos, neg, atb) # Binary Pattern
#feature2 = feature_calc(pos, neg, pat) #paac
feature4

df = pd.concat([feature1, feature2, feature3,feature4] , axis =1)
df

df = df.drop(['class2'] , axis = 1)
df

df = df.drop(['class3'] , axis = 1)
df

df = df.drop(['class4'] , axis = 1)
df

df = df.fillna('0')

from sklearn.feature_selection import VarianceThreshold

fs = VarianceThreshold(threshold=0.1)
fs.fit_transform(X)
#X2.shape
X = X.loc[:, fs.get_support()]
X

X = feature3.drop('class3', axis=1)
y = feature3['class3'].copy()

X

y

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state =73, stratify=y)

X_train = X_train.fillna(X_train.mean())

X_test = X_test.fillna(X_test.mean())

import pandas as pd

from Pfeature.pfeature import aac_wp

def aac(input):
  a = input.rstrip('txt')
  output = a + 'aac.csv'
  df_out = aac_wp(input, output)
  df_in = pd.read_csv(output)
  return df_in

  X4 = aac('/content/StraPep_peptide.txt')

X4 = aac('/content/StraPep_peptide.txt')
X4

from Pfeature.pfeature import aab_wp

def aab(input):
  a = input.rstrip('txt')
  output = a + 'aab.csv'
  df_out = aab_wp(input, output)
  df_in = pd.read_csv(output)
  return df_in
  X5 = aab('/content/BP0039.txt')

X5 = aab('/content/StraPep_peptide.txt')
X5

from Pfeature.pfeature import pcb_wp

def pcb(input):
  a = input.rstrip('txt')
  output = a + 'pcb.csv'
  df_out = pcb_wp(input, output)
  df_in = pd.read_csv(output)
  return df_in
  X6 = pcb('/content/StraPep_peptide.txt')

X6 = pcb('/content/StraPep_peptide.txt')
X6

from Pfeature.pfeature import pcp_wp

def pcp(input):
  a = input.rstrip('txt')
  output = a + 'pcp.csv'
  df_out = pcp_wp(input, output)
  df_in = pd.read_csv(output)
  return df_in
  X7 = pcp('/content/StraPep_peptide.txt')

X7 = pcp('/content/StraPep_peptide.txt')
X7

df5 = pd.concat([X4, X5, X6, X7], axis =1)
df5

X6 = X6.fillna(X6.mean())

df5 = df5.fillna('0')

"""**LightGBM**"""

import lightgbm as lgb
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn import metrics

#LGBM classifier Model
model = lgb.LGBMClassifier(learning_rate=0.09,max_depth=-5,random_state=42)
model.fit(X_train,y_train,eval_set=[(X_train,y_train)],
          verbose=20,eval_metric='logloss')

y_train_pred = model.predict(X_train)
y_test_pred = model.predict(X_test)

y_train_pred

y_test_pred

# Accuracy LGBM Test Set
from sklearn.metrics import accuracy_score

accuracy_score(y_test, y_test_pred)

# Accuracy LGBM Train Set
accuracy_score(y_train, y_train_pred)

# Matthew Correlation Coefficient
from sklearn.metrics import matthews_corrcoef

matthews_corrcoef(y_test, y_test_pred)

matthews_corrcoef(y_train, y_train_pred)

# Confusion matrix
from sklearn.metrics import confusion_matrix

confusion_matrix(y_test, y_test_pred)

confusion = metrics.confusion_matrix(y_test,y_test_pred)
TP = confusion[1,1]
TN= confusion[0,0]
FP = confusion[0,1]
FN = confusion[1,0]

#Sensitivity Score
TP / float(TP +FN)

#Specificity
TN/ float(TN+FP)

(TP + TN) / float (TP+TN+FP+FN)

# Retrieve feature importance from the RF model
importance = pd.Series(model.feature_importances_, name ='Gini')

# Retrieve feature names
feature_names = pd.Series(X.columns, name = 'Feature')

# Classification report
from sklearn.metrics import classification_report

model_report = classification_report(y_train, y_train_pred, target_names=['ACP','non-ACP'])

f = open('model_report.txt','w')
f.writelines(model_report)
f.close()
model_report

# ROC curve
import matplotlib.pyplot as plt
from sklearn.metrics import plot_roc_curve

plot_roc_curve(model, X_test, y_test)
plt.ylabel('True Positive Rate: ACP')
plt.xlabel('False Positive Rate:non-ACP')
plt.show()

plot_roc_curve(model, X_train, y_train)
plt.show()

df = pd.concat([feature_names, importance], axis=1, names=['Feature', 'Gini'])
df

plt.hist(X.AAC_K,alpha=.75,)
plt.ylabel('AAC_K')
plt.xlabel('score')
plt.grid(True)

import seaborn as sns
sns.distplot(X.AAC_K,kde=True,bins=10)

sns.distplot(X.AAC_C,kde=True,bins=10)

sns.distplot(X.AAC_R,kde=True,bins=10)

sns.boxplot(y="AAC_K",x="class",data=df)

sns.boxplot(y="AAC_R",x="class",data=df)

sns.violinplot(y="AAC_K",x="class",data=df)

sns.lmplot(x="AAC_K",y="AAC_R",data=df,fit_reg=False)

df= df[ ["AAC_A","AAC_C","AAC_K","AAC_L","AAC_S","AAC_T","NCF1","NCY1","NCT4","NCM3","NCF2"] ]

plt.figure(figsize = (16,5))
df.corr()#correlation ,this is value 1 to -1 it shows matrix
ax = sns.heatmap(df.corr(),annot=True) #annot it shows corr value

import pandas as pd
import numpy as np;np.random.seed(1)
import matplotlib.pyplot as plt

df = pd.DataFrame({"AAC_L" : np.random.exponential(size=100),
                   "class" : np.random.choice([1,0],100)})

_, edges = np.histogram(df["AAC_L"], bins=10)
histdata = []; labels=[]
for n, group in df.groupby("class"):
    histdata.append(np.histogram(group["AAC_L"], bins=edges)[0])
    labels.append(n)

hist = np.array(histdata)
histcum = np.cumsum(hist,axis=0)

plt.bar(edges[:-1],hist[0,:], width=np.diff(edges)[0],
            label=labels[0], align="edge")

for i in range(1,len(hist)):
    plt.bar(edges[:-1],hist[i,:], width=np.diff(edges)[0],
            bottom=histcum[i-1,:],label=labels[i], align="edge")

plt.legend(title="class")
plt.show()

# Plot of feature importance
import matplotlib.pyplot as plt
import seaborn as sns

df_sorted = df.sort_values('Gini', ascending=False)[:50] # Sort by Gini in descending order; Showing only the top 20 results

plt.figure(figsize=(10, 20))
sns.set_theme(style="whitegrid")
ax = sns.barplot(x = 'Gini', y = 'Feature', data = df_sorted)
plt.xlabel("Feature Importance")

import numpy as np
y_train_pred = model.predict(X6)

y_train_pred

import pandas as pd
pred2 =pd.DataFrame(y_train_pred)
pred2

pred2.value_counts()

probability_class = model.predict_proba(X6)
probability_class

prob = pd.DataFrame(probability_class, columns =['ACP','non-ACP'])
prob

"""**Random Forest**"""

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(n_estimators=200,
 max_depth =80,)

rf.fit(X_train, y_train)



y_train_pred = rf.predict(X_train)
y_test_pred = rf.predict(X_test)

# Simplest and quickest way to obtain the model performance (Accuracy)
rf.score(X_test,y_test)

# Accuracy
from sklearn.metrics import accuracy_score

accuracy_score(y_test, y_test_pred)

from sklearn.metrics import matthews_corrcoef

matthews_corrcoef(y_test, y_test_pred)

# Confusion matrix
from sklearn.metrics import confusion_matrix

confusion_matrix(y_test, y_test_pred)

# ROC curve
import matplotlib.pyplot as plt
from sklearn.metrics import plot_roc_curve

plot_roc_curve(rf, X_test, y_test)
plt.show()

plot_roc_curve(rf, X_train, y_train)
plt.show()

confusion = metrics.confusion_matrix(y_test,y_test_pred)
TP = confusion[1,1]
TN= confusion[0,0]
FP = confusion[0,1]
FN = confusion[1,0]

#Sensitivity
TP / float(TP +FN)

#Specificity
TN/ float(TN+FP)

import numpy as np
y_train_pred = rf.predict(X6)

import pandas as pd
pred1 =pd.DataFrame(y_train_pred)
pred1

pred1.value_counts()

probability_class = rf.predict_proba(X6)
probability_class

prob = pd.DataFrame(probability_class, columns =['ACP', 'non-ACP'])
prob

"""**DecsionTree**"""

# Load libraries
import pandas as pd
from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier
from sklearn.model_selection import train_test_split # Import train_test_split function
from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation

# Create Decision Tree classifer object
clf = DecisionTreeClassifier()

# Train Decision Tree Classifer
clf = clf.fit(X_train,y_train)

y_train_pred = clf.predict(X_train)
y_test_pred = clf.predict(X_test)

from sklearn.metrics import accuracy_score

accuracy_score(y_test, y_test_pred)

# Matthew Correlation Coefficient
from sklearn.metrics import matthews_corrcoef

matthews_corrcoef(y_test, y_test_pred)

y_train_pred = clf.predict(X6)

import pandas as pd
pred3 =pd.DataFrame(y_train_pred)
pred3

pred3.value_counts()

probability_class = clf.predict_proba(X6)
probability_class

prob = pd.DataFrame(probability_class, columns = ['ACP', 'non-ACP'])
prob

# Confusion matrix
from sklearn.metrics import confusion_matrix

confusion_matrix(y_test, y_test_pred)

import matplotlib.pyplot as plt
from sklearn.metrics import plot_roc_curve

plot_roc_curve(clf, X_test, y_test)
plt.show()

plot_roc_curve(clf, X_train, y_train)
plt.show()

confusion = metrics.confusion_matrix(y_test,y_test_pred)
TP = confusion[1,1]
TN= confusion[0,0]
FP = confusion[0,1]
FN = confusion[1,0]

#Sensitivity
TP / float(TP +FN)

#Specificity
TN/ float(TN+FP)

"""**ExtraTreeClassifier**"""

from sklearn.tree import ExtraTreeClassifier
clf2 = ExtraTreeClassifier( random_state = 23)
clf2.fit(X_train, y_train)

y_train_pred = clf2.predict(X_train)
y_test_pred = clf2.predict(X_test)

from sklearn.metrics import accuracy_score

accuracy_score(y_test, y_test_pred)

from sklearn.metrics import matthews_corrcoef

matthews_corrcoef(y_test, y_test_pred)

y_train_pred = clf2.predict(X6)
y_train_pred

import pandas as pd
pred4 =pd.DataFrame(y_train_pred)
pred4

pred4.value_counts()

clf2.predict_proba(X6)

pd.DataFrame(clf2.predict_proba(X6),columns = ['ACP','non-ACP'])

# Confusion matrix
from sklearn.metrics import confusion_matrix

confusion_matrix(y_test, y_test_pred)

import matplotlib.pyplot as plt
from sklearn.metrics import plot_roc_curve

plot_roc_curve(clf2, X_test, y_test)
plt.show()

plot_roc_curve(clf, X_train, y_train)
plt.show()

confusion = metrics.confusion_matrix(y_test,y_test_pred)
TP = confusion[1,1]
TN= confusion[0,0]
FP = confusion[0,1]
FN = confusion[1,0]

#Sensitivity
TP / float(TP +FN)

#Specificity
TN/ float(TN+FP)

"""**XGBClassifier**"""

from xgboost import XGBClassifier

xgbc = XGBClassifier()
print(xgbc)
XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,
       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,
       n_estimators=100, n_jobs=1, nthread=None,
       objective='multi:softprob', random_state=0, reg_alpha=0,
       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,
       subsample=1, verbosity=1)

xgbc.fit(X_train, y_train)
y_train_pred = xgbc.predict(X_train)
y_test_pred = xgbc.predict(X_test)

accuracy_score(y_test, y_test_pred)

matthews_corrcoef(y_test, y_test_pred)

y_train_pred = xgbc.predict(X6)
y_train_pred

import pandas as pd
pred5 =pd.DataFrame(y_train_pred)
pred5

pred5.value_counts()

xgbc.predict_proba(X6)

pd.DataFrame(xgbc.predict_proba(X6),columns = ['ACP','non-ACP'])

# Confusion matrix
from sklearn.metrics import confusion_matrix

confusion_matrix(y_test, y_test_pred)

import matplotlib.pyplot as plt
from sklearn.metrics import plot_roc_curve

plot_roc_curve(xgbc, X_test, y_test)
plt.show()

plot_roc_curve(xgbc, X_train, y_train)
plt.show()

confusion = metrics.confusion_matrix(y_test,y_test_pred)
TP = confusion[1,1]
TN= confusion[0,0]
FP = confusion[0,1]
FN = confusion[1,0]

#Sensitivity
TP / float(TP +FN)

#Specificity
TN/ float(TN+FP)

"""**SVM Model**"""

from sklearn.svm import SVC
clf3 = SVC(kernel='rbf', C=1e9, gamma=1e-07, probability=True)
clf3.fit(X_train, y_train)

y_test_pred = clf3.predict(X_test)
y_train_pred = clf3.predict(X_train)

accuracy_score(y_test, y_test_pred)

matthews_corrcoef(y_test, y_test_pred)

y_train_pred = clf3.predict(X6)
y_train_pred

import pandas as pd
pred6 =pd.DataFrame(y_train_pred)
pred6

pred6.value_counts()

clf3.predict_proba(X6)

prob = pd.DataFrame(clf3.predict_proba(X6), columns = ['ACP','non-ACP'])
prob

# Confusion matrix
from sklearn.metrics import confusion_matrix

confusion_matrix(y_test, y_test_pred)

import matplotlib.pyplot as plt
from sklearn.metrics import plot_roc_curve

plot_roc_curve(clf3, X_test, y_test)
plt.show()

plot_roc_curve(clf3, X_train, y_train)
plt.show()

confusion = metrics.confusion_matrix(y_test,y_test_pred)
TP = confusion[1,1]
TN= confusion[0,0]
FP = confusion[0,1]
FN = confusion[1,0]

#Sensitivity
TP / float(TP +FN)

#Specificity
TN/ float(TN+FP)

"""**BaggingClassifier**"""

from sklearn.svm import SVC
from sklearn.ensemble import BaggingClassifier
clf4 = BaggingClassifier(base_estimator = SVC(), random_state = 23)
clf4.fit(X_train,y_train)

y_test_pred = clf4.predict(X_test)
y_train_pred = clf4.predict(X_train)

from sklearn.metrics import accuracy_score
accuracy_score(y_test, y_test_pred)

from sklearn.metrics import matthews_corrcoef

matthews_corrcoef(y_test, y_test_pred)

y_train_pred = clf4.predict(X6)

import pandas as pd
pred7 =pd.DataFrame(y_train_pred)
pred7

pred7.value_counts()

clf4.predict_proba(X6)

df = pd.DataFrame(clf4.predict_proba(X6), columns = ['ACP','non-ACP'])
df

# Confusion matrix
from sklearn.metrics import confusion_matrix

confusion_matrix(y_test, y_test_pred)

import matplotlib.pyplot as plt
from sklearn.metrics import plot_roc_curve

plot_roc_curve(clf4, X_test, y_test)
plt.show()

plot_roc_curve(clf4, X_train, y_train)
plt.show()

confusion = metrics.confusion_matrix(y_test,y_test_pred)
TP = confusion[1,1]
TN= confusion[0,0]
FP = confusion[0,1]
FN = confusion[1,0]

#Sensitivity
TP / float(TP +FN)

#Specificity
TN/ float(TN+FP)

disp = plot_roc_curve(model, X_test,y_test)
plot_roc_curve(rf, X_test, y_test,ax = disp.ax_);
plot_roc_curve(clf, X_test, y_test,ax = disp.ax_);
plot_roc_curve(clf2, X_test, y_test,ax = disp.ax_);
plot_roc_curve(xgbc, X_test, y_test,ax = disp.ax_);
plot_roc_curve(clf3, X_test, y_test,ax = disp.ax_);
plot_roc_curve(clf4, X_test, y_test,ax = disp.ax_);
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('1-Specificity(False Positive Rate)')
plt.ylabel('Sensitivity(True Positive Rate)')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()

